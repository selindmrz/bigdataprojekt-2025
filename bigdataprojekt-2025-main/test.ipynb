{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np          #Berechnung von Matrizen\n",
    "import random               #Generierung zufälliger Zahlen oder anderer zufälliger Operationen\n",
    "import matplotlib as plt    #Erstellung von Diagrammen\n",
    "#import torch                #PyTorch Bibliothek \n",
    "#import torch.nn as nn\n",
    "#import torchvision          #Verarbeitung von Bildern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (20000, 128, 128, 3)\n",
      "y_train shape: (20000,)\n",
      "x_test shape: (5000, 128, 128, 3)\n",
      "y_test shape: (5000,)\n"
     ]
    }
   ],
   "source": [
    "# Parameter definieren\n",
    "image_folder = \"train/\"  # Ordner mit den Bildern\n",
    "image_size = (128, 128)  # Zielgröße der Bilder\n",
    "\n",
    "# Listen für Bilder und Labels initialisieren\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# ImageDataGenerator für Datenaugmentation definieren\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,         # Zufällige Rotation im Bereich von 0 bis 40 Grad\n",
    "    width_shift_range=0.2,     # Zufällige horizontale Verschiebung\n",
    "    height_shift_range=0.2,    # Zufällige vertikale Verschiebung\n",
    "    shear_range=0.2,           # Zufällige Scherung\n",
    "    zoom_range=0.2,            # Zufälliger Zoom\n",
    "    horizontal_flip=True,      # Zufälliges Spiegeln der Bilder\n",
    "    fill_mode='nearest'        # Auffüllen von Pixeln nach Transformationen\n",
    ")\n",
    "\n",
    "# Durch den Ordner iterieren und Bilder laden\n",
    "for filename in os.listdir(image_folder):\n",
    "    # Pfad zum Bild erstellen\n",
    "    img_path = os.path.join(image_folder, filename)\n",
    "\n",
    "    # Bild laden und auf die Zielgröße skalieren\n",
    "    img = load_img(img_path, target_size=image_size)\n",
    "    img_array = img_to_array(img) / 255.0  # Normalisieren auf [0, 1]\n",
    "\n",
    "    # Augmentierung durchführen\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Eine Batch-Dimension hinzufügen\n",
    "    augmented_image = datagen.random_transform(img_array[0])  # Augmentiertes Bild\n",
    "\n",
    "    # Augmentiertes Bild hinzufügen\n",
    "    images.append(augmented_image)\n",
    "\n",
    "    # Label bestimmen (dog = 1, cat = 0)\n",
    "    if \"dog\" in filename.lower():\n",
    "        labels.append(1)\n",
    "    elif \"cat\" in filename.lower():\n",
    "        labels.append(0)\n",
    "\n",
    "# In NumPy-Arrays umwandeln\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Daten in Trainings- und Validierungsdaten aufteilen\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 127s 201ms/step - loss: 0.6777 - accuracy: 0.5629 - val_loss: 0.6440 - val_accuracy: 0.6392\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 128s 205ms/step - loss: 0.6149 - accuracy: 0.6579 - val_loss: 0.5852 - val_accuracy: 0.6946\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 127s 203ms/step - loss: 0.5749 - accuracy: 0.6991 - val_loss: 0.5455 - val_accuracy: 0.7294\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 126s 202ms/step - loss: 0.5480 - accuracy: 0.7222 - val_loss: 0.5541 - val_accuracy: 0.7254\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 128s 205ms/step - loss: 0.5203 - accuracy: 0.7408 - val_loss: 0.5352 - val_accuracy: 0.7304\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 137s 218ms/step - loss: 0.4957 - accuracy: 0.7592 - val_loss: 0.4866 - val_accuracy: 0.7616\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 129s 207ms/step - loss: 0.4679 - accuracy: 0.7782 - val_loss: 0.4689 - val_accuracy: 0.7818\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 121s 193ms/step - loss: 0.4441 - accuracy: 0.7904 - val_loss: 0.4446 - val_accuracy: 0.7870\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 120s 192ms/step - loss: 0.4274 - accuracy: 0.8030 - val_loss: 0.4351 - val_accuracy: 0.8026\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 131s 209ms/step - loss: 0.3948 - accuracy: 0.8230 - val_loss: 0.4024 - val_accuracy: 0.8196\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 129s 207ms/step - loss: 0.3740 - accuracy: 0.8303 - val_loss: 0.4196 - val_accuracy: 0.8106\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 124s 198ms/step - loss: 0.3541 - accuracy: 0.8456 - val_loss: 0.3876 - val_accuracy: 0.8232\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 121s 194ms/step - loss: 0.3345 - accuracy: 0.8493 - val_loss: 0.3821 - val_accuracy: 0.8342\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 115s 184ms/step - loss: 0.3198 - accuracy: 0.8620 - val_loss: 0.3864 - val_accuracy: 0.8344\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 116s 186ms/step - loss: 0.3032 - accuracy: 0.8673 - val_loss: 0.3702 - val_accuracy: 0.8394\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 114s 182ms/step - loss: 0.2871 - accuracy: 0.8752 - val_loss: 0.3756 - val_accuracy: 0.8354\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 113s 182ms/step - loss: 0.2691 - accuracy: 0.8824 - val_loss: 0.3774 - val_accuracy: 0.8350\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 113s 180ms/step - loss: 0.2592 - accuracy: 0.8886 - val_loss: 0.3827 - val_accuracy: 0.8346\n"
     ]
    }
   ],
   "source": [
    "# CNN-Modell\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(128, 128, 3)),                     # Form der Eingabedaten: 128x128 Pixel, 3 Farbkanäle\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),          # 2D-Faltung zur Extraktion von Merkmalen; 32 Filter mit einer Größe von 3x3; ReLU-Aktivierungsfunktion\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),                           # Dimensionsreduktion; Pooling-Größe von 2x2\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),          \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)), \n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),         \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),                                      # Umwandlung der 2D-Ausgabe in ein 1D-Array\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),                  # 2 Ausgabeneuronen; Softmax Aktivierungsfunktion \n",
    "])\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer= 'adam',  # Optimierte Lernrate\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trainingsstopp, sobald der Validierungsgenauigkeit beginnt zu sinken\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# Training starten\n",
    "EPOCHS = 20                              \n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train,  \n",
    "    epochs=EPOCHS,   \n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bigdataprojekt-2025)",
   "language": "python",
   "name": "bigdataprojekt-2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
